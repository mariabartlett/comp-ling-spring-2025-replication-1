---
title: A Replication of _Measuring and Explaining Political Sophistication through Textual Complexity_ (Benoit et al., 2019)
subtitle: "PPOL 6801: Text as Data: Computational Linguistics"
author: "Wendy Shi & Maria Bartlett"
date: "February 11, 2025"
format:
  revealjs: 
    theme: bootstrap.scss
    embed-resources: true
editor: visual
---

```{r}

# clear global environment
rm(list = ls())

# set seed
set.seed(12345)

# load packages
library(tidyverse)
library(png)
library(grid)
library(spacyr)
library(sophistication)  
library(BradleyTerry2)
library(modelsummary)
library(quanteda)
library(quanteda.textstats)
library(assertr)
library(randomForest) 
library(kableExtra)

# set relative paths
root       <- file.path(getwd() %>% dirname())
author_rep <- file.path(root,"02_DataverseMaterials","dataverse_files")

```

# Introduction

## Background {.smaller}

Authors seek to contribute to a key gap in literature: **How to empirically measure the sophistication of [*political*]{style="color: #FFC107"} texts?**

-   *Why is sophistication important to measure?*

    -   Concern that political communication is becoming too simplistic

    -   Interest in studying potential causality between textual clarity and social science outcomes (e.g., levels of voter awareness)

-   *What measures already exist?*

    -   Many measures emerged from [*educational and psychology research*]{style="color: #FFC107"}, most popularly the [**Flesch Reading Ease (FRE)** score]{style="color: #FFC107"} (0-121 scale)

    -   Nevertheless, these measures have been used in a range of research, including in political text analysis

$$
\small
FRE = 206.835 - 1.015(\frac{total\ number\ of\ words}{total\ number\ of\ sentences}) \small - 84.6(\frac{total\ number\ of\ syllables}{total\ number\ of\ words})
$$

## Background {.smaller}

-   *What are the issues with using FRE and similar measures in political science research?*

    -   **Not domain-specific:** Developed in 1948 to assess U.S. student reading proficiency

    -   **Strong assumptions of what composes textual sophistication:** For example, FRE formula does not directly include a measure for frequently- vs. rarely-used words

    -   **No uncertainty mechanism:** Not feasible to construct standard errors for estimates

    -   **No natural ability to make comparisons:** FRE score units do not carry inherent meaning and there is no mechanism to convert scores into probabilities

## Roadmap of authors' goals {.smaller}

**These questions lead the authors to two main goals:**

1.  Re-explore determinants of textual sophistication, specifically in a political context

2.  Develop a model for political textual complexity that can be applied to any political text

**Key connections to our coursework:**

1.  Measures of textual ease

2.  Supervised learning models in textual analysis

# Methods

## Data {.smaller}

-   Corpus: 70 State of the Union (SOTU) speeches post-1950

-   Divided into "snippets"

-   Given two snippets, manual coders determine "easier" snippet (no ties!):

    -   Pairwise comparisons of snippets of similar length

    -   At least 3 coders per pair

    -   No snippet appears in isolation, thus make comparison between all pairs possible.

    -   7,236 total pairings for comparison (836 gold questions and 310 screeners to test coder fidelity/attention)

-   **Grand total of 19,810 comparisons**

## Sample of a text comparison

**Text 1:**

```         
"Under my Executive Order 12044, we required agencies to analyze the costs of their major new rules and consider alternative approaches-such as performance standards and voluntary codes-that may make rules less costly and more flexible.  We created the Regulatory Analysis Review Group in the White House to analyze the most costly proposed new rules and find ways to improve them." -- Carter 1981
```

**Text 2:**

```         
"We also show compassion abroad because regions overwhelmed by poverty, corruption, and despair are sources of terrorism and organized crime and human trafficking and the drug trade.  In recent years, you and I have taken unprecedented action to fight AIDS and malaria, expand the education of girls, and reward developing nations that are moving forward with economic and political reform." -- Bush 2006
```

## Bradley-Terry model {.smaller}

-   Model is designed for pairwise comparison (traditionally used to measure "ability")

-   Authors leverage Bradley-Terry design to compute easiness $(a_i)$ of a text

-   If the easiness of snippet $i$ s easier than the snippet $j$, the possibility of $i$ easier than $j$ is $a_i/a_j$

-   Define $\lambda_i = log\ a_i$

$$
Logit\ [Pr(i\ easier\ than\ j)] = \lambda_i - \lambda_j \\
= log (\frac{a_i}{a_j})
$$

-   Between two texts, which is easier

-   Easiness as compared to a benchmark

## Model covariates {.smaller}

Authors assume that a complex text uses:

-   Lengthier words more often

-   Rarer words more often **(keeping in mind that word rarity differs depending on time period)**

-   Lengthier sentences

-   Advanced grammar and syntax organization (e.g., subordinate clauses)

## Complete list of potential covariates {.smaller}

```{r, echo = FALSE}

img <- readPNG("table1.png")
grid.raster(img)

```

## Covariate generation {.smaller}

```{r, echo = TRUE, eval = FALSE}

library(quanteda)
library(sophistication)
library(BradleyTerry2)
library(tidyverse)

# load human-coded data of SOTU passages from CrowdFlower
allsentences <- rbind(read.csv(file.path(author_rep,"CF_output_f999866.csv"), stringsAsFactors = FALSE),
                      read.csv(file.path(author_rep,"CF_output_f952737.csv"), stringsAsFactors = FALSE)) 

# add covariates to prepare data for BT Model
job999866covars_chameleons <-
    bt_input_make(allsentences, 
                  covars = TRUE,
                  # measures text difficulty
                  readability_measure = c("Flesch", 
                                          "Dale.Chall",
                                          "FOG", 
                                          "SMOG",
                                          "Spache",
                                          "Coleman.Liau"),
                  # measures of word rarity (Google and Brown)
                  covars_baseline = TRUE, 
                  # measures of parts of speech
                  covars_pos = TRUE,
                  normalize = TRUE)

```

## Snapshot: Data at this point in time

```{r}
#| warning: false
#| output: asis
#| echo: false
#| eval: true

# load human-coded data of SOTU passages from CrowdFlower
allsentences <- rbind(read.csv(file.path(author_rep,"CF_output_f999866.csv"), stringsAsFactors = FALSE),
                      read.csv(file.path(author_rep,"CF_output_f952737.csv"), stringsAsFactors = FALSE)) %>%
  # confirm file is unique on id level
  verify(anyDuplicated(select(.,c(X_id))) == 0) %>%
  # check dimensions of data
  verify(nrow(.) == 27807 & ncol(.) == 25) %>%
  # confirm all tainted responses have been removed, per codebook
  verify(X_tainted == "false")

# add covariates to prepare data for BT Model
job999866covars_chameleons <-
    bt_input_make(allsentences, 
                  # add covariates for each snippet, taken directly from Crowdflower saved data
                  covars = TRUE,
                  # specify measures of text difficulty
                  readability_measure = c("Flesch", 
                                          "Dale.Chall",
                                          "FOG", 
                                          "SMOG",
                                          "Spache",
                                          "Coleman.Liau"),
                  # measures of word rarity (Google and Brown)
                  covars_baseline = TRUE, 
                  # measures of parts of speech
                  covars_pos = TRUE, 
                  # normalize covariates
                  normalize = TRUE)

# extract dataframe with covariates
pred_data <- job999866covars_chameleons$predictors %>%
  mutate(easier_id = row.names(.),
         harder_id = row.names(.))

# extract snippet 1 from each comparison
snippet_data1 <- allsentences %>%
  select(snippetid1,text1) %>%
  rename(snippetid = snippetid1,
         text      = text1) %>%
  distinct()

# extract snippet 2 from each comparison
snippet_data2 <- allsentences %>%
  select(snippetid2,text2) %>%
  rename(snippetid = snippetid2,
         text      = text2) %>%
  distinct()

# stack both sets of snippets and de-duplicate
snippet_data <- bind_rows(snippet_data1,snippet_data2) %>%
  distinct() %>%
  mutate(snippetid = as.character(snippetid))

# examine raw text snippet pairs alongside their corresponding covariates to ensure 
# we fully understand how covariate generation occurs
# --------------------------------------------------------------------------------
# extract 'easier' data
covars_data <- job999866covars_chameleons$easier %>%
  rename(easier_id = ID) %>%
  # merge with 'harder' data
  bind_cols(.,job999866covars_chameleons$harder) %>%
  rename(harder_id = ID) %>%
  # confirm number of rows has remained the same
  verify(nrow(.) == 19430) %>%
  # join m:1 with covariates for 'easier' snippet
  left_join(pred_data, by = "easier_id", relationship = "many-to-one") %>%
  # prefix all covariates with 'easier_' to specify these are covariates for 'easier' snippet
  rename_with(~ paste0("easier_", .), -c(harder_id.x,harder_id.y,easier_id)) %>%
  select(-harder_id.y) %>%
  rename(harder_id = harder_id.x) %>%
  # join m:1 with covariates for 'harder' snippet
  left_join(pred_data, by = "harder_id", relationship = "many-to-one") %>%
  # prefix all covariates with 'harder_' to specify these are covariates corresponding to 'harder' snippet
  rename_with(~ paste0("harder_", .), -c(starts_with("harder"),starts_with("easier"))) %>%
  select(-easier_id.y) %>%
  rename(easier_id = easier_id.x) %>%
  # merge on full text for easier snippets
  left_join(snippet_data, by = c("easier_id" = "snippetid")) %>%
  rename(easier_text = text) %>%
  # merge on full text for harder snippets
  left_join(snippet_data, by = c("harder_id" = "snippetid")) %>%
  rename(harder_text = text) %>%
  # confirm all snippets matched with their corresponding text
  verify(!is.na(easier_text) & !is.na(harder_text)) %>%
  # move text extracts up to front of file
  relocate(easier_text, .after = easier_id) %>%
  relocate(harder_text, .after = harder_id) 

covars_data %>%
  head(1) %>%
  kbl(full_width = T, 
      align = "l",
      booktabs = T) %>%
  kable_styling(latex_options = c("repeat_header","scale_down","HOLD_position"), font_size = 12) 

```

## Random forest for feature selection {.smaller}

-   Authors run random forest model (1,000 trees) to identify covariates most predictive of text ease

-   Based on node purity scores from random forest model, authors choose one covariate from each of their four categories of textual complexity:

    -   **Long Words:** `meanWordSyllables`

    -   **Rare Words:** `google_min`

    -   **Long Sentences:** `meanSentenceChars`

    -   **Complex Structure:** `pr_noun`

## Run 4 model specifications {.smaller}

```{r, echo = TRUE, eval = FALSE}

# Bradley-Terry 1: control only for baseline FRE score
BT_basic_Flesch <- BTm(player1 = easier, player2 = harder,
                       formula = ~ Flesch[ID], id = "ID",
                       data = job999866covars_chameleons)

# Bradley-Terry 2: control for FRE components (sentence length, word syllables), allowing for reweighting
BT_optimal_Flesch <- BTm(player1 = easier, player2 = harder, 
                         formula = ~ meanSentenceLength[ID] + meanWordSyllables[ID], 
                         id = "ID", data = job999866covars_chameleons)

# Bradley-Terry 3: control for 3 of 4 top covariates identified from random forest feature selection
BT_basic_RF <- BTm(player1 = easier, player2 = harder, 
                   formula = ~ google_min_2000[ID] + meanSentenceChars[ID] + pr_noun[ID], 
                   id ="ID", data = job999866covars_chameleons)

# Bradley-Terry 4: control for 4 top covariates identified from random forest feature selection
BT_best <- BTm(player1 = easier, player2 = harder, 
               formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] + pr_noun[ID] + meanWordChars[ID], 
               id = "ID", data = job999866covars_chameleons)
```

# Results

## Best model {.smaller}

**Model 4** (controlling for all four covariates from feature selection) performs best in terms of:

-   Lowest Akaike information criterion (AIC)

-   Highest proportion of comparisons accurately predicted

-   $\hat\beta$s from model 4 are used to construct $\hat\lambda$ probabilities that a text is easier relative to another

```{css, echo=FALSE}
.scrollable {
  overflow-y: auto;
  height: 90vh;
}
```

::: scrollable
## Best model {.smaller}

```{r}
#| warning: false
#| output: asis
#| echo: false
#| eval: true

# load respective author workspace
load(file.path(author_rep,"job999866covars_chameleons.rda"))

# Bradley-Terry 1: control only for baseline FRE score
BT_basic_Flesch <- BTm(player1 = easier, player2 = harder,
                       formula = ~ Flesch[ID], id = "ID",
                       data = job999866covars_chameleons)

# Bradley-Terry 2: control for FRE components (sentence length, word syllables), allowing for reweighting
BT_optimal_Flesch <- BTm(player1 = easier, player2 = harder, 
                         formula = ~ meanSentenceLength[ID] + meanWordSyllables[ID], 
                         id = "ID", data = job999866covars_chameleons)

# Bradley-Terry 3: control for 3 of 4 top covariates identified from random forest feature selection
BT_basic_RF <- BTm(player1 = easier, player2 = harder, 
                   formula = ~ google_min_2000[ID] + meanSentenceChars[ID] + pr_noun[ID], 
                   id ="ID", data = job999866covars_chameleons)

# Bradley-Terry 4: control for 4 top covariates identified from random forest feature selection
BT_best <- BTm(player1 = easier, player2 = harder, 
               formula = ~ google_min_2000[ID] +  meanSentenceChars[ID] + pr_noun[ID] + meanWordChars[ID], 
               id = "ID", data = job999866covars_chameleons)

# save results from four models
model_results <- list(BT_basic_Flesch = BT_basic_Flesch, 
                      BT_basic_RF = BT_basic_RF, 
                      BT_optimal_Flesch = BT_optimal_Flesch, 
                      BT_best = BT_best)
```
:::

## Validation: Comparing to FRE {.smaller}

```{r, echo = FALSE}

# get FRE scores for the snippets
dat <- job999866covars_chameleons
FRE <- dat$predictors$Flesch

names(FRE) <- rownames(dat$predictors)

# get lambdas from BMS best fitting model
main_lambdas <- BTabilities(BT_best)[,"ability"]

# rescale lambdas to the 0-100 space correctly
rescaled_lambdas <- 226.06927 + 57.93899 * main_lambdas

# check that they are matched up
m <- match(names(FRE), names(rescaled_lambdas)) ## they are matched up

ggplot(data.frame(FRE = FRE, rslambda = rescaled_lambdas), aes(x = FRE, y = rslambda)) +
    geom_point(size = .6) +
    labs(y = "Rescaled Best BT Model") +
    geom_smooth(method = "lm", se = TRUE) +
    geom_hline(yintercept = c(0, 100), linetype = "dashed", color = "firebrick") +
    theme(axis.text.x = element_text(size = 5),
          axis.text.y = element_text(size = 5)) +
    theme_classic()

```

# Autopsy/Differences

## Autopsy/Differences {.smaller}

-   Able to replicate feature selection results, model results, and key plots

-   Authors wrote `sophistication` package and replication materials rely heavily on this package; had some initial start-up issues because this package is not actively maintained on GitHub

-   One package authors use is no longer maintained on CRAN

# Extension

## Extension {.smaller}

**Code updates:**

-   Modernized some of the approaches, particularly with data wrangling, to use more of the `tidyverse`

-   Added data checks and amplified comments to add additional clarity

**Substantive proposals:**

-   Improved model testing (model was trained on all coder data)

-   Improved model validation beyond comparing against FRE score

-   Run model on different political text (e.g., campaign speeches)

-   Could consider other machine learning approaches besides random forest for feature selection

-   With more resources (would require hiring coders!) change outcome variable in Bradley-Terry model to different measure of interest (e.g., tone)

## References {.smaller}

Benoit, Kenneth, Kevin Munger, and Arthur Spirling. 2019. "Measuring and Explaining Political Sophistication through Textual Complexity." *American Journal of Political Science* 63 (2): 491--508.doi: 10.1111/ajps.12423

Benoit, Kenneth, 2019, "Replication Data for: Measuring and Explaining Political Sophistication Through Textual Complexity", https://doi.org/10.7910/DVN/9SF3TI, Harvard Dataverse, V1, UNF:6:3lWCX52gHXjVfaeDpmEBPQ== \[fileUNF\]
